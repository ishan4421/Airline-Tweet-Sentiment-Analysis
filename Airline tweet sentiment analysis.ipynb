{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed140b60-f9c4-42e9-b16e-e9014957b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f04fc59-356d-4221-a66f-7b9a614ffab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_11768\\2645341026.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01memoji\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196edbc1-3218-46ef-8ce1-c019e712dca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emojiNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading emoji-2.10.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Downloading emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n",
      "   ---------------------------------------- 0.0/421.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/421.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/421.5 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 61.4/421.5 kB 1.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 92.2/421.5 kB 1.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 225.3/421.5 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 358.4/421.5 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 358.4/421.5 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 358.4/421.5 kB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 399.4/421.5 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  419.8/421.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  419.8/421.5 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- 421.5/421.5 kB 876.9 kB/s eta 0:00:00\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.10.1\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a04c7055-b7c4-4585-8ff3-3fa8bbd0e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67a1f821-4530-4436-87ab-4f98b0b54d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb9ea42-c947-4d40-a064-8537569f8a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4a71dd-b2f3-415e-bc50-2576af44f308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f9fd5af-7b01-408f-942d-f3cd8009724e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b52bb519-3560-42be-ad7a-bea15f139601",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_threshold= 0.6\n",
    "data= data.drop(data.query('airline_sentiment_confidence < @confidence_threshold').index, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93ea0abf-48b0-4111-9397-56f6752b3497",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df= pd.concat([data['text'], data['airline_sentiment']], axis=1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb0d53f8-ba4a-4452-a1c3-5b65591fcd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14397</th>\n",
       "      <td>@AmericanAir right on cue with the delays👌</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14398</th>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14399</th>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14400</th>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14401</th>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14402 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment\n",
       "0                    @VirginAmerica What @dhepburn said.           neutral\n",
       "1      @VirginAmerica I didn't today... Must mean I n...           neutral\n",
       "2      @VirginAmerica it's really aggressive to blast...          negative\n",
       "3      @VirginAmerica and it's a really big bad thing...          negative\n",
       "4      @VirginAmerica seriously would pay $30 a fligh...          negative\n",
       "...                                                  ...               ...\n",
       "14397         @AmericanAir right on cue with the delays👌          negative\n",
       "14398  @AmericanAir leaving over 20 minutes Late Flig...          negative\n",
       "14399  @AmericanAir Please bring American Airlines to...           neutral\n",
       "14400  @AmericanAir you have my money, you change my ...          negative\n",
       "14401  @AmericanAir we have 8 ppl so we need 2 know h...           neutral\n",
       "\n",
       "[14402 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb324b96-a40f-4d2b-a04b-9bbe8ed30bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_ordering=['negative','neutral', 'positive']\n",
    "tweets_df['airline_sentiment']= tweets_df['airline_sentiment'].apply(lambda x: sentence_ordering.index(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88395221-9110-4528-a5fd-aeee3e405757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14397</th>\n",
       "      <td>@AmericanAir right on cue with the delays👌</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14398</th>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14399</th>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14400</th>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14401</th>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14402 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  airline_sentiment\n",
       "0                    @VirginAmerica What @dhepburn said.                  1\n",
       "1      @VirginAmerica I didn't today... Must mean I n...                  1\n",
       "2      @VirginAmerica it's really aggressive to blast...                  0\n",
       "3      @VirginAmerica and it's a really big bad thing...                  0\n",
       "4      @VirginAmerica seriously would pay $30 a fligh...                  0\n",
       "...                                                  ...                ...\n",
       "14397         @AmericanAir right on cue with the delays👌                  0\n",
       "14398  @AmericanAir leaving over 20 minutes Late Flig...                  0\n",
       "14399  @AmericanAir Please bring American Airlines to...                  1\n",
       "14400  @AmericanAir you have my money, you change my ...                  0\n",
       "14401  @AmericanAir we have 8 ppl so we need 2 know h...                  1\n",
       "\n",
       "[14402 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf0ef316-b0a5-4ed7-bef5-8dac549461b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps= PorterStemmer()\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    new_tweet= tweet.lower()\n",
    "    new_tweet= re.sub(r'@\\w+', '',new_tweet)\n",
    "    new_tweet= re.sub(r'#', '',new_tweet)\n",
    "    new_tweet= re.sub(r':', ' ',emoji.demojize(new_tweet))\n",
    "    new_tweet = re.sub(r'http\\S+', '',new_tweet) # Remove URLs\n",
    "    new_tweet = re.sub(r'\\$\\S+', 'dollar', new_tweet) # Change dollar amounts to dollar\n",
    "    new_tweet = re.sub(r'[^a-z0-9\\s]', '', new_tweet) # Remove punctuation\n",
    "    new_tweet = re.sub(r'[0-9]+', 'number', new_tweet) # Change number values to number\n",
    "    new_tweet = new_tweet.split(\" \")\n",
    "    new_tweet = list(map(lambda x: ps.stem(x), new_tweet)) # Stemming the words\n",
    "    new_tweet = list(map(lambda x: x.strip(), new_tweet)) # Stripping whitespace from the words\n",
    "    if '' in new_tweet:\n",
    "        new_tweet.remove('')\n",
    "    return new_tweet\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdcdb4d7-77eb-4072-b1cc-d1846326b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets_df['text'].apply(process_tweet)\n",
    "\n",
    "labels = np.array(tweets_df['airline_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc3321fc-67cb-424b-8c4e-c480c500d352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           [what, , said]\n",
       "1        [i, didnt, today, must, mean, i, need, to, tak...\n",
       "2        [it, realli, aggress, to, blast, obnoxi, enter...\n",
       "3         [and, it, a, realli, big, bad, thing, about, it]\n",
       "4        [serious, would, pay, dollar, a, flight, for, ...\n",
       "                               ...                        \n",
       "14397           [right, on, cue, with, the, delay, hand, ]\n",
       "14398    [leav, over, number, minut, late, flight, no, ...\n",
       "14399    [pleas, bring, american, airlin, to, blackberr...\n",
       "14400    [you, have, my, money, you, chang, my, flight,...\n",
       "14401    [we, have, number, ppl, so, we, need, number, ...\n",
       "Name: text, Length: 14402, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "022b1881-6bad-460a-a680-802a157c753a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab length: 11250\n",
      "Max sequence length: 90\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set()\n",
    "\n",
    "for tweet in tweets:\n",
    "    for word in tweet:\n",
    "        if word not in vocabulary:\n",
    "            vocabulary.add(word)\n",
    "\n",
    "vocab_length = len(vocabulary)\n",
    "\n",
    "\n",
    "max_seq_length = 0\n",
    "\n",
    "for tweet in tweets:\n",
    "    if len(tweet) > max_seq_length:\n",
    "        max_seq_length = len(tweet)\n",
    "\n",
    "\n",
    "print(\"Vocab length:\", vocab_length)\n",
    "print(\"Max sequence length:\", max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd03d34c-0c9e-470e-a3e6-4291abfad52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_length)\n",
    "tokenizer.fit_on_texts(tweets)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(tweets)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "model_inputs = pad_sequences(sequences, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a4dfd11-63a1-4a53-ab4e-2421f628f2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  49,    2,  218, ...,    0,    0,    0],\n",
       "       [   5,  191,  102, ...,    0,    0,    0],\n",
       "       [  15,  138, 2841, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  76,  507,  435, ...,    0,    0,    0],\n",
       "       [   8,   19,   12, ...,    0,    0,    0],\n",
       "       [  37,   19,    4, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "641e44af-ac3a-42e9-b2e5-aa7cb0acf09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14402, 90)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a7bf014-7893-4664-8b22-76af118eed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(model_inputs, labels, train_size=0.7, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3aa917ce-989f-4c89-b656-aea71f8f7277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 32\n",
    "\n",
    "\n",
    "inputs = tf.keras.Input(shape=(max_seq_length,))\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=vocab_length,\n",
    "    output_dim=embedding_dim,\n",
    "    \n",
    ")(inputs)\n",
    "\n",
    "\n",
    "# Model A (just a Flatten layer)\n",
    "flatten = tf.keras.layers.Flatten()(embedding)\n",
    "\n",
    "# Model B (GRU with a Flatten layer)\n",
    "gru = tf.keras.layers.GRU(units=embedding_dim)(embedding)\n",
    "gru_flatten = tf.keras.layers.Flatten()(gru)\n",
    "\n",
    "# Both A and B are fed into the output\n",
    "concat = tf.keras.layers.concatenate([flatten, gru_flatten])\n",
    "\n",
    "outputs = tf.keras.layers.Dense(3, activation='softmax')(concat)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8fdf533-3487-4f88-a54d-b2c2976f18b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 42ms/step - accuracy: 0.6176 - loss: 0.8769 - val_accuracy: 0.7194 - val_loss: 0.6568 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.7826 - loss: 0.5501 - val_accuracy: 0.7799 - val_loss: 0.5317 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.8687 - loss: 0.3827 - val_accuracy: 0.7893 - val_loss: 0.5039 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9097 - loss: 0.2795 - val_accuracy: 0.8022 - val_loss: 0.5024 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9371 - loss: 0.2100 - val_accuracy: 0.7987 - val_loss: 0.5126 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9548 - loss: 0.1599 - val_accuracy: 0.7972 - val_loss: 0.5354 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9698 - loss: 0.1252 - val_accuracy: 0.7942 - val_loss: 0.5565 - learning_rate: 0.0010\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b8105a5-78ef-4bff-afab-37ffa8db09a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8002 - loss: 0.5118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4932244122028351, 0.8060634136199951]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10894080-de01-479b-bbcb-d7838bef1dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
